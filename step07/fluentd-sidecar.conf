<source>
  @id fluentd-containers.log
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/containers.log.pos
  tag raw.kubernetes.*
  read_from_head true
  <parse>
	@type multi_format
	<pattern>
	  format json
	  time_key time
	  time_format %Y-%m-%dT%H:%M:%S.%NZ
	</pattern>
	<pattern>
	  format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
	  time_format %Y-%m-%dT%H:%M:%S.%N%:z
	</pattern>
  </parse>
</source>

# Detect exceptions in the log output and forward them as one log entry.
<match raw.kubernetes.**>
  @id raw.kubernetes
  @type detect_exceptions
  remove_tag_prefix raw
  message log
  stream stream
  multiline_flush_interval 5
  max_bytes 500000
  max_lines 1000
</match>

# Concatenate multi-line logs
<filter **>
  @id filter_concat
  @type concat
  key message
  multiline_end_regexp /\n$/
  separator ""
</filter>

# Enriches records with Kubernetes metadata
<filter kubernetes.**>
  @id filter_kubernetes_metadata
  @type kubernetes_metadata
</filter>

# Fixes json fields in Elasticsearch
<filter kubernetes.**>
  @id filter_parser
  @type parser
  key_name log
  reserve_data true
  remove_key_name_field true
  <parse>
	@type multi_format
	<pattern>
	  format json
	</pattern>
	<pattern>
	  format none
	</pattern>
  </parse>
</filter>

<match **>
  @id elasticsearch
  @type elasticsearch
  @log_level info
  include_tag_key true
  type_name _doc
  host elasticsearch-master
  port 9200
  scheme http
  ssl_version TLSv1_2
  ssl_verify true
  logstash_format true
  logstash_prefix logstash
  reconnect_on_error true
  <buffer>
	@type file
	path /var/log/fluentd-buffers/kubernetes.system.buffer
	flush_mode interval
	retry_type exponential_backoff
	flush_thread_count 2
	flush_interval 5s
	retry_forever
	retry_max_interval 30
	chunk_limit_size 2M
	queue_limit_length 8
	overflow_action block
  </buffer>
</match>
